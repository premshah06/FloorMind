# FloorMind - AI-Powered Floor Plan Generator

## Project Documentation

**Version:** 1.0.0 (Production)  
**Last Updated:** November 27, 2025  
**Status:** Production Ready

---

## 1. Introduction

### What is FloorMind?

FloorMind is an AI-powered text-to-floor-plan generation system that transforms natural language descriptions into detailed architectural floor plans. The project leverages fine-tuned Stable Diffusion models trained on the CubiCasa5K dataset (5,050 architectural floor plans) to generate high-quality, realistic floor plan images from textual prompts.

### Problem Statement

Traditional floor plan creation requires:
- Specialized architectural software (AutoCAD, SketchUp)
- Professional expertise and training
- Significant time investment (hours to days per plan)
- Iterative back-and-forth with clients

FloorMind solves this by enabling instant floor plan generation from simple text descriptions like "modern 3-bedroom apartment with open kitchen and balcony."

### Domain

- **Primary Domain:** Architecture & Real Estate Technology
- **Application Type:** Full-stack web application with AI/ML backend
- **Target Users:** Architects, real estate developers, interior designers, homeowners

---

## 2. Purpose & Objectives

### Main Goals

1. **Democratize Floor Plan Design**: Make architectural visualization accessible to non-professionals
2. **Accelerate Design Iteration**: Generate multiple design variations in seconds vs. hours
3. **AI-Powered Creativity**: Leverage deep learning to explore novel architectural layouts
4. **Production-Ready System**: Deliver a complete, deployable application with frontend and backend

### Expected Outcomes

- Generate 512√ó512px floor plan images in 20-60 seconds (CPU) or 2-5 seconds (GPU)
- Achieve 71.7% accuracy on architectural layout generation
- Support diverse architectural styles (modern, traditional, contemporary, etc.)
- Provide RESTful API for easy integration with other systems
- Enable batch generation for design exploration

### Value Proposition

- **Time Savings**: 100x faster than manual CAD design
- **Cost Reduction**: No expensive software licenses required
- **Accessibility**: Natural language interface requires no technical training
- **Scalability**: Generate unlimited variations for A/B testing and client presentations

---

## 3. Software Requirements

### Programming Languages

- **Python 3.8+** (Backend, ML training, data processing)
- **JavaScript (ES6+)** (Frontend - React)
- **Bash** (Deployment scripts)

### Backend Frameworks & Libraries

#### Core ML/AI Stack
- `torch==2.0.0` - PyTorch deep learning framework
- `diffusers==0.25.0` - Hugging Face diffusion models library
- `transformers==4.36.0` - CLIP text encoder and tokenizers
- `accelerate==0.25.0` - Distributed training and optimization
- `safetensors==0.4.1` - Safe model serialization format
- `peft` (LoRA/QLoRA) - Parameter-efficient fine-tuning

#### Web Framework
- `flask==3.0.0` - Lightweight web server
- `flask-cors==4.0.0` - Cross-origin resource sharing

#### Image Processing
- `Pillow==10.1.0` - Image manipulation and I/O
- `opencv-python` - Advanced image processing
- `numpy==1.24.3` - Numerical computing

#### Data & Utilities
- `pandas` - Data manipulation and CSV handling
- `requests==2.31.0` - HTTP client
- `matplotlib` - Visualization and plotting
- `seaborn` - Statistical data visualization
- `scikit-learn` - Train/test splitting and metrics

### Frontend Stack

#### Core Framework
- `react==18.2.0` - UI component library
- `react-dom==18.2.0` - React DOM rendering
- `react-router-dom==6.3.0` - Client-side routing
- `react-scripts==5.0.1` - Create React App build tools

#### UI/UX Libraries
- `tailwindcss==3.3.2` - Utility-first CSS framework
- `framer-motion==10.12.16` - Animation library
- `lucide-react==0.263.1` - Icon library
- `react-hot-toast==2.4.1` - Toast notifications

#### Data Visualization
- `recharts==2.7.2` - Chart components

#### HTTP Client
- `axios==1.4.0` - Promise-based HTTP client

### External Services & APIs

- **Hugging Face Hub** - Model hosting and distribution
- **Google Gemini API** (Optional) - Enhanced text generation and analysis
- **Stable Diffusion 2.1** - Base model from StabilityAI

### Environment Variables

Required configuration (`.env` file):
```bash
# Optional: Google Gemini API
GEMINI_API_KEY=your_api_key_here

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True

# Model Configuration
DEFAULT_MODEL=gemini
ENABLE_3D_FEATURES=True

# File Upload
MAX_UPLOAD_SIZE=16777216  # 16MB
ALLOWED_EXTENSIONS=png,jpg,jpeg,gif

# Output Paths
OUTPUT_DIR=../outputs
SAMPLE_GENERATIONS_DIR=../outputs/sample_generations
METRICS_DIR=../outputs/metrics

# Performance
GENERATION_TIMEOUT=30  # seconds
MAX_BATCH_SIZE=10
```

### Database Requirements

**None** - FloorMind is stateless and file-based:
- Model weights stored in `models/` directory
- Generated images saved to `generated_floor_plans/` or `output/generated/`
- Metadata stored in CSV files (`data/metadata.csv`)

---

## 4. Hardware Requirements

### Minimum Requirements (Development)

**For CPU-Only Inference:**
- **CPU:** 4-core processor (Intel i5/AMD Ryzen 5 or better)
- **RAM:** 16GB minimum (32GB recommended)
- **Storage:** 20GB free space
  - 5GB for model weights
  - 5GB for dataset (if training)
  - 10GB for outputs and cache
- **OS:** macOS, Linux, or Windows 10/11

**Performance:** ~30-60 seconds per 512√ó512 image

### Recommended Requirements (Production)

**For GPU-Accelerated Inference:**
- **GPU:** NVIDIA GPU with 8GB+ VRAM
  - RTX 3060 (12GB) - Good
  - RTX 3080 (10GB) - Better
  - RTX 4090 (24GB) - Best
  - A100 (40GB/80GB) - Enterprise
- **CPU:** 8-core processor
- **RAM:** 32GB
- **Storage:** 50GB SSD
- **CUDA:** 11.8+ with cuDNN

**Performance:** ~2-5 seconds per 512√ó512 image

### Training Requirements

**For Fine-Tuning (LoRA/QLoRA):**
- **GPU:** NVIDIA GPU with 16GB+ VRAM
  - T4 (16GB) - Minimum (Google Colab Free)
  - A100 (40GB) - Recommended (Google Colab Pro)
  - A100 (80GB) - Optimal (Google Colab Pro+)
- **RAM:** 32GB system RAM
- **Storage:** 100GB+ for dataset and checkpoints
- **Training Time:** 
  - 4-6 hours for 15-20 epochs on A100
  - 12-24 hours on T4

**For Full Fine-Tuning (Not Recommended):**
- **GPU:** 2√óA100 (80GB) minimum
- **RAM:** 128GB+
- **Storage:** 500GB+

### Cloud Deployment Options

1. **Google Colab** (Training)
   - Free Tier: T4 GPU (limited hours)
   - Pro: A100 40GB ($10/month)
   - Pro+: A100 80GB ($50/month)

2. **AWS EC2** (Production Inference)
   - g4dn.xlarge: T4 GPU, 16GB VRAM (~$0.50/hour)
   - g5.xlarge: A10G GPU, 24GB VRAM (~$1.00/hour)
   - p3.2xlarge: V100 GPU, 16GB VRAM (~$3.00/hour)

3. **Hugging Face Spaces** (Demo Hosting)
   - CPU: Free
   - GPU: $0.60/hour

4. **Local Development**
   - CPU-only: Any modern laptop
   - GPU: Desktop with NVIDIA GPU

### Special Hardware Notes

- **Apple Silicon (M1/M2/M3):** Supported via MPS backend, but slower than NVIDIA CUDA
- **AMD GPUs:** Not officially supported (ROCm experimental)
- **CPU Inference:** Fully functional but 10-20x slower than GPU
- **Memory Optimization:** Attention slicing and gradient checkpointing reduce VRAM usage by 30-40%

---

## 5. Tech Stack & What Is Used

### Backend Architecture

#### 1. **Flask REST API** (`backend/api/app.py`)
- **Role:** HTTP server exposing generation endpoints
- **Port:** 5001
- **Endpoints:**
  - `GET /health` - Health check and status
  - `GET /model/info` - Model metadata
  - `POST /model/load` - Load AI model into memory
  - `POST /generate` - Generate single floor plan
  - `POST /generate/batch` - Generate multiple variations
  - `GET /presets` - Get example prompts

#### 2. **Model Loader** (`backend/core/model_loader.py`)
- **Role:** Manages Stable Diffusion pipeline lifecycle
- **Features:**
  - Automatic model discovery (searches `models/active/`)
  - Device management (CPU/CUDA/MPS)
  - Memory optimization (attention slicing, xFormers)
  - Graceful error handling

#### 3. **Diffusion Pipeline** (Stable Diffusion 2.1)
- **Components:**
  - **UNet** (3.3GB) - Denoising network (fine-tuned)
  - **VAE** (319MB) - Image encoder/decoder
  - **CLIP Text Encoder** (1.3GB) - Text ‚Üí embeddings
  - **Scheduler** - Noise scheduling (DPMSolver++)
- **Resolution:** 512√ó512 pixels
- **Inference Steps:** 20-50 (default: 20)
- **Guidance Scale:** 5.0-12.0 (default: 7.5)

### Frontend Architecture

#### 1. **React Single-Page Application**
- **Entry Point:** `frontend/src/index.js`
- **Main Component:** `frontend/src/App.jsx`
- **Routing:** React Router v6
- **Pages:**
  - `HomePage.js` - Landing page with features
  - `GeneratorPage.js` - Main generation interface
  - `ModelsPage.js` - Model information and metrics
  - `MetricsPage.js` - Performance analytics
  - `DevelopersPage.js` - Team information
  - `AboutPage.js` - Project details

#### 2. **API Service Layer** (`frontend/src/services/api.js`)
- **Role:** Centralized HTTP client with error handling
- **Features:**
  - Axios interceptors for logging
  - Automatic retry logic
  - Request/response transformation
  - Base64 image handling
- **Methods:**
  - `checkHealth()` - Server status
  - `loadModel()` - Initialize AI model
  - `generateFloorPlan()` - Single generation
  - `generateVariations()` - Batch generation
  - `getPresets()` - Example prompts
  - `downloadImage()` - Save generated images

#### 3. **UI Components**
- **Tailwind CSS** - Utility-first styling
- **Framer Motion** - Smooth animations and transitions
- **Lucide React** - Consistent iconography
- **React Hot Toast** - User notifications

### Training Pipeline

#### 1. **Data Processing** (`data/process_cubicasa5k_improved.py`)
- **Input:** CubiCasa5K raw dataset (5,050 floor plans)
- **Processing:**
  - Image resizing to 512√ó512 with aspect ratio preservation
  - Smart padding with white background
  - Contrast and sharpness enhancement
  - Metadata extraction from JSON annotations
- **Output:**
  - Processed images (PNG)
  - Numpy arrays (.npy) for fast loading
  - Train/test split (60/40)
  - Metadata CSV with descriptions

#### 2. **Training Scripts**
- **`final_best_fine.py`** - Production training with UNet + Text Encoder LoRA
  - LoRA rank: 32 (UNet), 16 (Text Encoder)
  - Learning rate: 5e-5 (UNet), 5e-6 (Text Encoder)
  - Epochs: 20
  - Batch size: 4 (A100) / 2 (T4)
  - Optimizer: AdamW with OneCycleLR scheduler
  
- **`train_production.py`** - Alternative training (UNet-only LoRA)
  - LoRA rank: 16
  - Learning rate: 5e-5
  - Epochs: 20
  - Simpler, faster training

- **`train_qlora.py`** - Quantized LoRA for memory efficiency
  - 8-bit quantization
  - Reduced memory footprint
  - Slightly lower quality

#### 3. **Training Features**
- Gradient checkpointing (saves 40% VRAM)
- Mixed precision (FP16)
- xFormers memory-efficient attention
- Validation image generation every 2 epochs
- Best model checkpointing
- Training curves and metrics logging

### Deployment & DevOps

#### 1. **Scripts** (`scripts/`)
- **Deployment:**
  - `start_server.sh` - Launch Flask backend
- **Testing:**
  - `test_api.py` - Comprehensive API tests
  - `verify_setup.py` - Installation verification
  - `check_model.py` - Model integrity checks
- **Utilities:**
  - `cleanup.sh` - Remove temporary files

#### 2. **Configuration**
- `config/backend_config.py` - Backend settings
- `config/training_config_a100.json` - Training hyperparameters
- `.env.example` - Environment variable template

### Build Tools

- **Frontend Build:** Create React App (Webpack, Babel)
- **Backend:** No build step (Python interpreted)
- **Model Packaging:** Diffusers `save_pretrained()` format

### Version Control

- **Git** - Source control
- **GitHub** - Repository hosting
- `.gitignore` - Excludes models, datasets, outputs

---

## 6. Methodology / Architecture & Design

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Frontend (React)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ GeneratorPage‚îÇ  ‚îÇ  ModelsPage  ‚îÇ  ‚îÇ  MetricsPage ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ         ‚îÇ                                                     ‚îÇ
‚îÇ         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ API Service (axios)                  ‚îÇ
‚îÇ                              ‚îÇ                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ HTTP/JSON
                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Backend (Flask REST API)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  app.py - Route Handlers                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /health, /model/info, /model/load                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /generate, /generate/batch, /presets              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                       ‚îÇ                                      ‚îÇ
‚îÇ                       ‚ñº                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  model_loader.py - Pipeline Management               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Model discovery and loading                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Device management (CPU/CUDA/MPS)                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Memory optimization                               ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                       ‚îÇ                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Stable Diffusion Pipeline (PyTorch)             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ CLIP Text    ‚îÇ  ‚îÇ  UNet 2D     ‚îÇ  ‚îÇ     VAE      ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ Encoder      ‚îÇ  ‚îÇ (Fine-tuned) ‚îÇ  ‚îÇ  Encoder/    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ (1.3GB)      ‚îÇ  ‚îÇ  (3.3GB)     ‚îÇ  ‚îÇ  Decoder     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ  (319MB)     ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ         ‚îÇ                 ‚îÇ                  ‚îÇ               ‚îÇ
‚îÇ         ‚ñº                 ‚ñº                  ‚ñº               ‚îÇ
‚îÇ    Text Embeddings ‚Üí Denoising Loop ‚Üí Image Decoding        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
                  Generated Floor Plan
                    (512√ó512 PNG)
```

### Data Flow

#### 1. **Generation Request Flow**

```
User Input (Text Prompt)
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Frontend: User types "modern 2-bedroom apartment"
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ API Service: POST /generate with parameters
    ‚îÇ   {
    ‚îÇ     "description": "modern 2-bedroom apartment...",
    ‚îÇ     "steps": 20,
    ‚îÇ     "guidance": 7.5,
    ‚îÇ     "seed": 42
    ‚îÇ   }
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Flask Backend: Receives request, validates input
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Model Loader: Checks if model is loaded
    ‚îÇ   ‚îú‚îÄ If not loaded: Load from disk (30-60 seconds)
    ‚îÇ   ‚îî‚îÄ If loaded: Use cached pipeline
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Text Encoding: CLIP encodes prompt ‚Üí embeddings (768-dim)
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Latent Initialization: Random noise (64√ó64√ó4 latent)
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Denoising Loop: 20 iterations
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Step 1: UNet predicts noise
    ‚îÇ   ‚îú‚îÄ Step 2: Scheduler removes predicted noise
    ‚îÇ   ‚îú‚îÄ Step 3: Apply guidance scale
    ‚îÇ   ‚îî‚îÄ Repeat...
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ VAE Decoding: Latent (64√ó64√ó4) ‚Üí Image (512√ó512√ó3)
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Post-Processing: Convert to PNG, encode base64
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Response: JSON with base64 image
    ‚îÇ   {
    ‚îÇ     "status": "success",
    ‚îÇ     "image": "data:image/png;base64,iVBOR...",
    ‚îÇ     "generation_time": 2.3
    ‚îÇ   }
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ Frontend: Display image, enable download
```

#### 2. **Training Data Flow**

```
CubiCasa5K Raw Dataset (5,050 floor plans)
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Data Processing (process_cubicasa5k_improved.py)
    ‚îÇ   ‚îú‚îÄ Load images and JSON annotations
    ‚îÇ   ‚îú‚îÄ Resize to 512√ó512 with padding
    ‚îÇ   ‚îú‚îÄ Extract room metadata
    ‚îÇ   ‚îú‚îÄ Generate text descriptions
    ‚îÇ   ‚îî‚îÄ Save as PNG + numpy arrays
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Train/Test Split (60/40)
    ‚îÇ   ‚îú‚îÄ Train: 3,030 samples
    ‚îÇ   ‚îî‚îÄ Test: 2,020 samples
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Training Loop (final_best_fine.py)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ Load Stable Diffusion 2.1 base model
    ‚îÇ   ‚îú‚îÄ Attach LoRA adapters to UNet + Text Encoder
    ‚îÇ   ‚îú‚îÄ Freeze VAE (no training)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ For each epoch (20 total):
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îú‚îÄ For each batch (size 4):
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Encode images to latents (VAE)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Encode text to embeddings (CLIP)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Add noise to latents
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Predict noise with UNet
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Compute MSE loss
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ Backpropagate (only LoRA weights)
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ Update optimizer
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îú‚îÄ Save checkpoint every 500 steps
    ‚îÇ   ‚îÇ   ‚îî‚îÄ Generate validation images every 2 epochs
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ Save final model (merge LoRA ‚Üí full weights)
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ Production Model
        ‚îú‚îÄ models/active/floormind_pipeline/
        ‚îÇ   ‚îú‚îÄ unet/ (3.3GB)
        ‚îÇ   ‚îú‚îÄ text_encoder/ (1.3GB)
        ‚îÇ   ‚îú‚îÄ vae/ (319MB)
        ‚îÇ   ‚îú‚îÄ tokenizer/
        ‚îÇ   ‚îî‚îÄ scheduler/
        ‚îî‚îÄ Ready for inference
```

### Core Components

#### 1. **UNet 2D Conditional Model** (Image Generator)
- **Architecture:** U-Net with cross-attention layers
- **Input:** Noisy latent (64√ó64√ó4) + text embeddings (77√ó768)
- **Output:** Predicted noise (64√ó64√ó4)
- **Parameters:** 865M (base) ‚Üí 867M (fine-tuned with LoRA)
- **Fine-Tuning:** LoRA adapters on attention layers
  - Target modules: `to_q`, `to_k`, `to_v`, `to_out.0`
  - Rank: 32, Alpha: 64
  - Trainable params: ~2M (0.2% of total)

#### 2. **CLIP Text Encoder** (Text Understanding)
- **Architecture:** Transformer encoder (12 layers)
- **Input:** Tokenized text (max 77 tokens)
- **Output:** Text embeddings (77√ó768)
- **Parameters:** 123M
- **Fine-Tuning:** Optional LoRA on attention layers
  - Target modules: `q_proj`, `k_proj`, `v_proj`, `out_proj`
  - Rank: 16, Alpha: 32
  - Trainable params: ~1M

#### 3. **VAE (Variational Autoencoder)** (Image Compression)
- **Architecture:** Encoder-Decoder CNN
- **Encoder:** Image (512√ó512√ó3) ‚Üí Latent (64√ó64√ó4)
- **Decoder:** Latent (64√ó64√ó4) ‚Üí Image (512√ó512√ó3)
- **Parameters:** 83M
- **Fine-Tuning:** Frozen (not trained)
- **Compression:** 8√ó spatial, 4√ó channel

#### 4. **Scheduler** (Noise Management)
- **Type:** DPMSolverMultistepScheduler
- **Steps:** 20-50 (default: 20)
- **Noise Schedule:** Scaled linear
- **Guidance:** Classifier-free guidance (scale: 7.5)

### Design Patterns

#### 1. **Singleton Pattern** (Model Loader)
```python
_model_loader = ModelLoader()

def get_model_loader() -> ModelLoader:
    return _model_loader
```
- Ensures only one model instance in memory
- Prevents redundant loading

#### 2. **Factory Pattern** (Dataset Creation)
```python
class ArchitecturalFloorPlanDataset(Dataset):
    def __init__(self, image_dir, resolution, augment):
        self.transform = self._get_transforms()
```
- Encapsulates dataset creation logic
- Supports different augmentation strategies

#### 3. **Strategy Pattern** (Device Management)
```python
if torch.cuda.is_available():
    device = "cuda"
elif torch.backends.mps.is_available():
    device = "mps"
else:
    device = "cpu"
```
- Adapts to available hardware
- Transparent to caller

#### 4. **Facade Pattern** (API Service)
```python
class FloorMindAPI:
    async def generateFloorPlan(params):
        # Hides complexity of HTTP, error handling, retries
```
- Simplifies frontend integration
- Centralizes error handling

### Important Design Decisions

#### 1. **Why LoRA Instead of Full Fine-Tuning?**
- **Memory:** 16GB VRAM vs. 80GB+ required
- **Speed:** 4-6 hours vs. 2-3 days training time
- **Quality:** 95% of full fine-tuning performance
- **Flexibility:** Easy to swap/merge adapters

#### 2. **Why Stable Diffusion 2.1 vs. SDXL?**
- **Size:** 5GB vs. 13GB model
- **Speed:** 2-5s vs. 10-15s per image
- **VRAM:** 8GB vs. 16GB minimum
- **Quality:** Sufficient for 512√ó512 floor plans

#### 3. **Why Flask Instead of FastAPI?**
- **Simplicity:** Minimal boilerplate
- **Maturity:** Well-documented, stable
- **Compatibility:** Easy integration with PyTorch
- **Deployment:** Works on any Python environment

#### 4. **Why React Instead of Vue/Svelte?**
- **Ecosystem:** Largest component library
- **Talent Pool:** Easier to find developers
- **Tooling:** Excellent dev tools and debugging
- **Community:** Most Stack Overflow answers

---

## 7. Setup & Installation

### Prerequisites

1. **Python 3.8+** installed
2. **Node.js 16+** and npm (for frontend)
3. **Git** for cloning the repository
4. **10GB+ free disk space**
5. **(Optional) NVIDIA GPU** with CUDA 11.8+ for faster inference

### Step-by-Step Installation

#### Step 1: Clone the Repository

```bash
git clone <repository-url>
cd FloorMind
```

#### Step 2: Backend Setup

```bash
# Create Python virtual environment
python3 -m venv venv

# Activate virtual environment
# On macOS/Linux:
source venv/bin/activate
# On Windows:
venv\Scripts\activate

# Install Python dependencies
pip install --upgrade pip
pip install -r requirements.txt
```

**Expected time:** 5-10 minutes (downloads ~2GB of packages)

#### Step 3: Download/Prepare the Model

**Option A: Use Pre-trained Model (Recommended)**

If you have access to the fine-tuned model:

```bash
# Place the model in the correct location
mkdir -p models/active
# Copy floormind_pipeline/ to models/active/

# Verify model structure
ls models/active/floormind_pipeline/
# Should show: scheduler/ text_encoder/ tokenizer/ unet/ vae/ model_index.json
```

**Option B: Train Your Own Model**

If you want to train from scratch:

```bash
# 1. Download CubiCasa5K dataset
cd data
bash download_cubicasa5k.sh  # Or manually download from Zenodo

# 2. Process the dataset
python process_cubicasa5k_improved.py

# 3. Train the model (requires GPU)
cd ../scripts/training
python final_best_fine.py
# This will take 4-6 hours on A100 GPU
```

#### Step 4: Configure Environment Variables

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your settings (optional)
nano .env
```

Most settings have sensible defaults and don't need changes.

#### Step 5: Frontend Setup (Optional)

```bash
cd frontend

# Install Node.js dependencies
npm install

# Build for production
npm run build

# Or run development server
npm start
```

**Expected time:** 3-5 minutes

#### Step 6: Verify Installation

```bash
# Run verification script
python scripts/testing/verify_setup.py
```

This checks:
- ‚úÖ All required files exist
- ‚úÖ Model integrity
- ‚úÖ Python dependencies
- ‚úÖ Directory structure

#### Step 7: Start the Backend Server

```bash
# Option A: Using the startup script
./scripts/deployment/start_server.sh

# Option B: Direct Python execution
python backend/api/app.py
```

The server will:
1. Load the AI model (30-60 seconds first time)
2. Start listening on `http://localhost:5001`
3. Display available endpoints

**Expected output:**
```
============================================================
üèóÔ∏è  FloorMind AI Backend Server
============================================================

üì¶ Loading AI model...
‚úÖ Model loaded successfully!
   Device: cpu
   Model: models/active/floormind_pipeline

üì° Available endpoints:
   GET  /health              - Health check
   GET  /model/info          - Model information
   POST /model/load          - Load model
   POST /generate            - Generate floor plan
   POST /generate/batch      - Generate variations
   GET  /presets             - Get example prompts

üöÄ Server starting on http://localhost:5001
============================================================
```

#### Step 8: Test the API

```bash
# In a new terminal, run the test suite
python scripts/testing/test_api.py
```

This will test:
- ‚úÖ Health check
- ‚úÖ Model loading
- ‚úÖ Presets retrieval
- ‚úÖ Single generation
- ‚úÖ Batch generation

### Configuration Files

#### `config/backend_config.py`

```python
HOST = "0.0.0.0"          # Listen on all interfaces
PORT = 5001               # Backend port
DEBUG = False             # Production mode

MODEL_PATH = "models/active/floormind_pipeline"
DEVICE = "cpu"            # or "cuda" for GPU
DTYPE = "float32"         # or "float16" for GPU

DEFAULT_STEPS = 20        # Inference steps
DEFAULT_GUIDANCE = 7.5    # Guidance scale
DEFAULT_WIDTH = 512       # Image width
DEFAULT_HEIGHT = 512      # Image height

OUTPUT_DIR = "output/generated"
```

#### `config/training_config_a100.json`

Training hyperparameters for A100 GPU:
- Batch size: 2-4
- Learning rate: 5e-6
- Epochs: 15
- Mixed precision: FP16
- Gradient checkpointing: Enabled

### Environment Variables

Create `.env` file:

```bash
# Flask
FLASK_ENV=development
FLASK_DEBUG=True

# Model
DEFAULT_MODEL=gemini
ENABLE_3D_FEATURES=True

# Paths
OUTPUT_DIR=../outputs
SAMPLE_GENERATIONS_DIR=../outputs/sample_generations
METRICS_DIR=../outputs/metrics

# Performance
GENERATION_TIMEOUT=30
MAX_BATCH_SIZE=10
```

### Troubleshooting Installation

#### Issue: "Model not found"

```bash
# Check model directory
ls -la models/active/floormind_pipeline/

# Verify UNet weights exist
ls -lh models/active/floormind_pipeline/unet/diffusion_pytorch_model.safetensors
```

**Solution:** Ensure the model is in the correct location with all components.

#### Issue: "CUDA out of memory"

```bash
# Force CPU mode
export FORCE_CPU=true
python backend/api/app.py
```

**Solution:** Use CPU mode or reduce batch size.

#### Issue: "Port 5001 already in use"

```bash
# Find and kill the process
lsof -ti:5001 | xargs kill -9

# Or change the port in config/backend_config.py
PORT = 5002
```

#### Issue: "Module not found"

```bash
# Reinstall dependencies
pip install --force-reinstall -r requirements.txt
```

#### Issue: "Frontend won't start"

```bash
cd frontend
rm -rf node_modules package-lock.json
npm install
npm start
```

---

## 8. Usage / How to Run

### Running the Backend Server

#### Method 1: Using the Startup Script (Recommended)

```bash
./scripts/deployment/start_server.sh
```

This script:
1. Activates virtual environment
2. Installs/updates dependencies
3. Starts the Flask server

#### Method 2: Direct Execution

```bash
# Activate virtual environment
source venv/bin/activate

# Start server
python backend/api/app.py
```

#### Method 3: Production Deployment

```bash
# Using Gunicorn (production WSGI server)
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5001 backend.api.app:app
```

### Running the Frontend

#### Development Mode

```bash
cd frontend
npm start
```

- Opens browser at `http://localhost:3000`
- Hot reload enabled
- Development tools available

#### Production Build

```bash
cd frontend
npm run build

# Serve the build
npx serve -s build -p 3000
```

### API Endpoints

#### 1. Health Check

```bash
curl http://localhost:5001/health
```

**Response:**
```json
{
  "status": "healthy",
  "service": "FloorMind AI",
  "version": "1.0.0",
  "model_loaded": true,
  "timestamp": "2025-11-27T10:30:00"
}
```

#### 2. Get Model Information

```bash
curl http://localhost:5001/model/info
```

**Response:**
```json
{
  "status": "success",
  "model": {
    "is_loaded": true,
    "device": "cpu",
    "dtype": "torch.float32",
    "model_path": "models/active/floormind_pipeline",
    "resolution": 512
  }
}
```

#### 3. Load Model

```bash
curl -X POST http://localhost:5001/model/load \
  -H "Content-Type: application/json" \
  -d '{"force_cpu": true}'
```

**Response:**
```json
{
  "status": "success",
  "message": "Model loaded successfully",
  "model_info": { ... }
}
```

#### 4. Generate Floor Plan

```bash
curl -X POST http://localhost:5001/generate \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Modern 3-bedroom apartment with open kitchen and balcony",
    "width": 512,
    "height": 512,
    "steps": 20,
    "guidance": 7.5,
    "seed": 42,
    "save": true
  }'
```

**Response:**
```json
{
  "status": "success",
  "description": "Modern 3-bedroom apartment...",
  "image": "data:image/png;base64,iVBORw0KGgoAAAANS...",
  "parameters": {
    "width": 512,
    "height": 512,
    "num_inference_steps": 20,
    "guidance_scale": 7.5,
    "seed": 42
  },
  "saved_path": "generated_floor_plans/floor_plan_20251127_103045.png",
  "timestamp": "2025-11-27T10:30:45"
}
```

#### 5. Generate Batch (Multiple Variations)

```bash
curl -X POST http://localhost:5001/generate/batch \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Cozy 2-bedroom apartment",
    "count": 4,
    "steps": 20,
    "guidance": 7.5,
    "seed": 100
  }'
```

**Response:**
```json
{
  "status": "success",
  "description": "Cozy 2-bedroom apartment",
  "count": 4,
  "variations": [
    {
      "index": 1,
      "image": "data:image/png;base64,...",
      "seed": 100
    },
    {
      "index": 2,
      "image": "data:image/png;base64,...",
      "seed": 101
    },
    ...
  ],
  "parameters": { ... },
  "timestamp": "2025-11-27T10:35:00"
}
```

#### 6. Get Presets

```bash
curl http://localhost:5001/presets
```

**Response:**
```json
{
  "status": "success",
  "presets": {
    "residential": [
      "Modern 3-bedroom apartment with open kitchen and living room",
      "Cozy 2-bedroom house with separate dining area",
      ...
    ],
    "commercial": [
      "Small office space with reception and meeting rooms",
      ...
    ],
    "styles": [
      "Minimalist apartment with clean lines",
      ...
    ]
  }
}
```

### Using the Web Interface

#### 1. Access the Generator

Navigate to `http://localhost:3000/generate` (or the deployed URL)

#### 2. Enter a Description

Type a natural language description:
- "Modern studio apartment with open kitchen"
- "3-bedroom house with garage and balcony"
- "Contemporary office space with meeting rooms"

#### 3. Adjust Parameters (Optional)

- **Quality (Steps):** 20-50 (higher = better quality, slower)
- **Guidance Scale:** 5-12 (higher = more faithful to prompt)
- **Architectural Style:** Modern, Traditional, Contemporary, etc.

#### 4. Generate

Click "Generate Floor Plan" and wait 30-60 seconds (CPU) or 2-5 seconds (GPU)

#### 5. Download

Click "Download Floor Plan" to save the generated image

### Sample Prompts

#### Residential

```
Modern 1-bedroom studio apartment with open layout
Cozy 2-bedroom apartment with separate kitchen and living room
Spacious 3-bedroom family apartment with master suite
Luxury 4-bedroom penthouse with balcony and walk-in closets
Traditional family home with garage and dining room
Contemporary loft with industrial design
```

#### Commercial

```
Small office space with reception area and meeting room
Open-plan coworking space with flexible seating
Retail store layout with customer area and storage
Restaurant floor plan with dining area and kitchen
Medical clinic with waiting room and exam rooms
```

#### Architectural Styles

```
Minimalist apartment with clean lines and efficient layout
Victorian house with traditional layout and formal rooms
Scandinavian-style compact living with natural light
Industrial loft conversion with exposed elements
Mediterranean villa with courtyard and open spaces
Japanese-inspired zen apartment with minimal furniture
```

### Testing the System

#### Run Full Test Suite

```bash
python scripts/testing/test_api.py
```

Tests:
- ‚úÖ Health check
- ‚úÖ Model loading
- ‚úÖ Presets retrieval
- ‚úÖ Single generation
- ‚úÖ Batch generation

#### Verify Setup

```bash
python scripts/testing/verify_setup.py
```

Checks:
- ‚úÖ Required files
- ‚úÖ Model integrity
- ‚úÖ Dependencies
- ‚úÖ Server status
- ‚úÖ API endpoints

#### Check Model Quality

```bash
python scripts/testing/check_model.py
```

Generates test images and evaluates quality.

### Performance Optimization

#### CPU Optimization

```python
# In backend/core/model_loader.py
self.pipeline.enable_attention_slicing()  # Reduces memory
```

#### GPU Optimization

```python
# Enable xFormers (faster attention)
self.pipeline.enable_xformers_memory_efficient_attention()

# Enable TF32 (Ampere+ GPUs)
torch.backends.cuda.matmul.allow_tf32 = True
```

#### Batch Processing

For multiple generations, use batch endpoint:
```bash
# 4 variations in one request (faster than 4 separate requests)
POST /generate/batch with count=4
```

### Monitoring & Logs

#### View Server Logs

```bash
# Real-time logs
tail -f training_production.log

# Search for errors
grep "ERROR" training_production.log
```

#### Check Generated Images

```bash
ls -lh generated_floor_plans/
# Shows all generated images with timestamps
```

#### Monitor GPU Usage (if applicable)

```bash
# NVIDIA GPU
watch -n 1 nvidia-smi

# Check VRAM usage
nvidia-smi --query-gpu=memory.used --format=csv
```

---

## 9. Problems Faced / Limitations (Code Perspective)

### Potential Challenges

#### 1. **Model Loading Time**

**Issue:** First model load takes 30-60 seconds on CPU, blocking the server.

**Location:** `backend/core/model_loader.py:load()`

**Impact:**
- Poor user experience on first request
- Frontend timeout if not handled properly

**Current Mitigation:**
- Auto-load model on server startup
- Frontend shows loading state
- Timeout set to 300 seconds

**Suggested Improvement:**
```python
# Implement async model loading with progress updates
async def load_model_async(self, progress_callback):
    # Stream loading progress to frontend via WebSocket
    pass
```

#### 2. **Memory Management**

**Issue:** Model requires 8-16GB RAM, can cause OOM on low-memory systems.

**Location:** `backend/core/model_loader.py:_optimize_pipeline()`

**Evidence:**
```python
# Current optimization
self.pipeline.enable_attention_slicing()  # Helps but not enough
```

**Impact:**
- Server crashes on memory-constrained systems
- Cannot run multiple concurrent generations

**Suggested Improvements:**
- Implement model unloading after idle timeout
- Add request queuing to prevent concurrent generations
- Use model quantization (8-bit/4-bit) for lower memory footprint

```python
# Proposed solution
class ModelLoader:
    def __init__(self):
        self.idle_timeout = 300  # 5 minutes
        self.last_used = time.time()
    
    def auto_unload_if_idle(self):
        if time.time() - self.last_used > self.idle_timeout:
            self.unload()
```

#### 3. **Error Handling Inconsistency**

**Issue:** Error handling varies across endpoints, some errors not user-friendly.

**Location:** `backend/api/app.py` - various endpoints

**Examples:**
```python
# Good error handling
except Exception as e:
    logger.error(f"Generation error: {e}")
    return jsonify({"status": "error", "error": str(e)}), 500

# Missing error handling in some routes
# No validation for invalid parameters
# Generic error messages don't help debugging
```

**Impact:**
- Difficult to debug issues
- Poor user experience
- Security risk (exposing stack traces)

**Suggested Improvements:**
- Centralized error handler
- Input validation middleware
- Structured error responses with error codes

```python
class APIError(Exception):
    def __init__(self, message, code, status_code):
        self.message = message
        self.code = code
        self.status_code = status_code

@app.errorhandler(APIError)
def handle_api_error(error):
    return jsonify({
        "status": "error",
        "error": error.message,
        "code": error.code
    }), error.status_code
```

#### 4. **No Request Queuing**

**Issue:** Concurrent requests can overload the system.

**Location:** `backend/api/app.py:generate_floor_plan()`

**Impact:**
- Multiple simultaneous generations cause OOM
- No fair scheduling (first-come-first-served)
- Server becomes unresponsive

**Suggested Improvement:**
```python
from queue import Queue
from threading import Thread

class GenerationQueue:
    def __init__(self, max_workers=1):
        self.queue = Queue()
        self.workers = []
        for _ in range(max_workers):
            worker = Thread(target=self._process_queue)
            worker.start()
            self.workers.append(worker)
    
    def add_request(self, request_id, params):
        self.queue.put((request_id, params))
        return {"status": "queued", "position": self.queue.qsize()}
```

#### 5. **Limited Validation**

**Issue:** Input validation is minimal, allowing invalid parameters.

**Location:** `backend/api/app.py:generate_floor_plan()`

**Examples:**
```python
# Current validation
if not data or 'description' not in data:
    return jsonify({"status": "error", "error": "Missing 'description'"}), 400

# Missing validations:
# - steps range (should be 1-100)
# - guidance range (should be 1-20)
# - width/height (should be multiples of 8)
# - description length (should be < 500 chars)
```

**Impact:**
- Invalid parameters cause cryptic errors
- Potential for abuse (extremely long prompts)
- Wasted computation on invalid requests

**Suggested Improvement:**
```python
from pydantic import BaseModel, Field, validator

class GenerationRequest(BaseModel):
    description: str = Field(..., min_length=10, max_length=500)
    steps: int = Field(20, ge=1, le=100)
    guidance: float = Field(7.5, ge=1.0, le=20.0)
    width: int = Field(512, ge=256, le=1024)
    height: int = Field(512, ge=256, le=1024)
    
    @validator('width', 'height')
    def validate_dimensions(cls, v):
        if v % 8 != 0:
            raise ValueError('Dimensions must be multiples of 8')
        return v
```

#### 6. **No Caching**

**Issue:** Identical prompts regenerate from scratch, wasting computation.

**Location:** `backend/api/app.py:generate_floor_plan()`

**Impact:**
- Repeated requests for same prompt take full generation time
- Unnecessary GPU/CPU usage
- Higher costs in cloud deployment

**Suggested Improvement:**
```python
import hashlib
from functools import lru_cache

class ImageCache:
    def __init__(self, max_size=100):
        self.cache = {}
        self.max_size = max_size
    
    def get_cache_key(self, prompt, params):
        key_str = f"{prompt}_{params['steps']}_{params['guidance']}_{params['seed']}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, key):
        return self.cache.get(key)
    
    def set(self, key, image):
        if len(self.cache) >= self.max_size:
            # Remove oldest entry
            self.cache.pop(next(iter(self.cache)))
        self.cache[key] = image
```

#### 7. **Frontend State Management**

**Issue:** No global state management, prop drilling in components.

**Location:** `frontend/src/pages/GeneratorPage.js`

**Evidence:**
```javascript
// Multiple useState hooks in one component
const [prompt, setPrompt] = useState('');
const [modelType, setModelType] = useState('baseline');
const [isGenerating, setIsGenerating] = useState(false);
const [generatedImage, setGeneratedImage] = useState(null);
// ... 10+ more state variables
```

**Impact:**
- Component becomes bloated (500+ lines)
- Difficult to test
- State synchronization issues
- Poor code reusability

**Suggested Improvement:**
```javascript
// Use Context API or Redux
import { createContext, useContext, useReducer } from 'react';

const GeneratorContext = createContext();

function generatorReducer(state, action) {
  switch (action.type) {
    case 'SET_PROMPT':
      return { ...state, prompt: action.payload };
    case 'START_GENERATION':
      return { ...state, isGenerating: true };
    // ...
  }
}

export function GeneratorProvider({ children }) {
  const [state, dispatch] = useReducer(generatorReducer, initialState);
  return (
    <GeneratorContext.Provider value={{ state, dispatch }}>
      {children}
    </GeneratorContext.Provider>
  );
}
```

#### 8. **No Database / Persistence**

**Issue:** No storage for generation history, user preferences, or analytics.

**Location:** Entire backend (file-based only)

**Impact:**
- Cannot track usage metrics
- No user accounts or saved generations
- Cannot implement rate limiting
- No audit trail

**Suggested Improvement:**
```python
# Add SQLite for lightweight persistence
import sqlite3

class GenerationHistory:
    def __init__(self, db_path='floormind.db'):
        self.conn = sqlite3.connect(db_path)
        self.create_tables()
    
    def create_tables(self):
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS generations (
                id INTEGER PRIMARY KEY,
                prompt TEXT,
                parameters JSON,
                image_path TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
    
    def save_generation(self, prompt, params, image_path):
        self.conn.execute(
            'INSERT INTO generations (prompt, parameters, image_path) VALUES (?, ?, ?)',
            (prompt, json.dumps(params), image_path)
        )
        self.conn.commit()
```

#### 9. **Training Script Complexity**

**Issue:** Training scripts are monolithic (1000+ lines), hard to maintain.

**Location:** `final_best_fine.py`, `scripts/training/train_production.py`

**Evidence:**
```python
# Single file contains:
# - Dataset class (200 lines)
# - Trainer class (600 lines)
# - Main function (100 lines)
# - Utility functions (100 lines)
```

**Impact:**
- Difficult to modify training logic
- Hard to add new features (e.g., different schedulers)
- Testing is challenging
- Code duplication across training scripts

**Suggested Improvement:**
```
training/
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ base_dataset.py
‚îÇ   ‚îî‚îÄ‚îÄ floor_plan_dataset.py
‚îú‚îÄ‚îÄ trainers/
‚îÇ   ‚îú‚îÄ‚îÄ base_trainer.py
‚îÇ   ‚îî‚îÄ‚îÄ lora_trainer.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ logging.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py
‚îî‚îÄ‚îÄ configs/
    ‚îú‚îÄ‚îÄ base_config.py
    ‚îî‚îÄ‚îÄ production_config.py
```

#### 10. **Incomplete Test Coverage**

**Issue:** Tests only cover API endpoints, no unit tests for core logic.

**Location:** `scripts/testing/` - only integration tests

**Missing Tests:**
- Model loader unit tests
- Dataset processing tests
- Image transformation tests
- Error handling tests
- Frontend component tests

**Impact:**
- Regressions go unnoticed
- Refactoring is risky
- Difficult to ensure quality

**Suggested Improvement:**
```python
# tests/unit/test_model_loader.py
import pytest
from backend.core.model_loader import ModelLoader

def test_model_loader_initialization():
    loader = ModelLoader()
    assert loader.pipeline is None
    assert loader.device in ['cpu', 'cuda', 'mps']

def test_model_loading():
    loader = ModelLoader()
    success = loader.load(force_cpu=True)
    assert success
    assert loader.is_loaded()

def test_generation():
    loader = ModelLoader()
    loader.load(force_cpu=True)
    result = loader.generate("test prompt", steps=10)
    assert 'image' in result
    assert result['image'].size == (512, 512)
```

### Known Limitations

#### 1. **Resolution Constraint**
- Fixed at 512√ó512 pixels
- Cannot generate higher resolution without retraining
- Upscaling post-processing degrades quality

#### 2. **Generation Speed**
- CPU: 30-60 seconds per image (too slow for production)
- GPU required for acceptable performance (2-5 seconds)

#### 3. **Prompt Understanding**
- Limited to architectural vocabulary
- Cannot handle complex spatial relationships
- No support for metric dimensions (e.g., "20 square meters")

#### 4. **No 3D Output**
- Only generates 2D floor plans
- No elevation views or 3D models
- Frontend has placeholder for 3D features

#### 5. **Single Language**
- Only supports English prompts
- No internationalization (i18n)

#### 6. **No Authentication**
- Open API with no access control
- No rate limiting
- Vulnerable to abuse

---

## 10. Conclusion & Future Work

### Project Summary

FloorMind successfully demonstrates the feasibility of AI-powered architectural floor plan generation using fine-tuned diffusion models. The project delivers a complete, production-ready system with:

**Strengths:**
- ‚úÖ **Functional AI Pipeline:** Successfully fine-tuned Stable Diffusion 2.1 on 5,050 architectural floor plans
- ‚úÖ **Complete Full-Stack Application:** React frontend + Flask backend with RESTful API
- ‚úÖ **Production Quality:** Clean code structure, comprehensive documentation, deployment scripts
- ‚úÖ **Reasonable Performance:** 71.7% accuracy, 2-5 seconds generation time on GPU
- ‚úÖ **User-Friendly Interface:** Intuitive web UI with real-time generation and download
- ‚úÖ **Extensible Architecture:** Modular design allows easy addition of new features

**Areas for Improvement:**
- ‚ö†Ô∏è **Memory Management:** High RAM requirements (8-16GB) limit deployment options
- ‚ö†Ô∏è **Error Handling:** Inconsistent error handling across endpoints
- ‚ö†Ô∏è **Scalability:** No request queuing or caching for concurrent users
- ‚ö†Ô∏è **Testing:** Limited unit test coverage, mostly integration tests
- ‚ö†Ô∏è **Persistence:** No database for history, analytics, or user management

### Software Engineering Assessment

**Code Quality: 7/10**
- Well-organized directory structure
- Clear separation of concerns (frontend/backend/training)
- Good documentation and comments
- Some code duplication in training scripts
- Inconsistent error handling

**Architecture: 8/10**
- Clean REST API design
- Proper use of design patterns (Singleton, Factory, Facade)
- Modular component structure
- Could benefit from dependency injection
- Missing middleware layer for validation

**Maintainability: 7/10**
- Clear file naming and organization
- Comprehensive inline documentation
- Some monolithic files (1000+ lines)
- Limited unit tests make refactoring risky
- Good use of configuration files

**Performance: 7/10**
- Efficient LoRA fine-tuning approach
- Good memory optimizations (attention slicing, xFormers)
- No caching or request queuing
- CPU performance is poor (30-60s per image)
- GPU performance is acceptable (2-5s per image)

**Security: 5/10**
- No authentication or authorization
- No rate limiting
- No input sanitization beyond basic validation
- CORS enabled for all origins
- No HTTPS enforcement

### Future Enhancements

#### Short-Term Improvements (1-3 months)

**1. Performance Optimization**
```python
# Implement request queuing
class RequestQueue:
    def __init__(self, max_concurrent=1):
        self.queue = asyncio.Queue()
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_request(self, request):
        async with self.semaphore:
            return await self.generate(request)
```

**2. Caching Layer**
```python
# Add Redis for distributed caching
import redis
from functools import wraps

cache = redis.Redis(host='localhost', port=6379)

def cache_generation(ttl=3600):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            cache_key = generate_cache_key(args, kwargs)
            cached = cache.get(cache_key)
            if cached:
                return pickle.loads(cached)
            result = func(*args, **kwargs)
            cache.setex(cache_key, ttl, pickle.dumps(result))
            return result
        return wrapper
    return decorator
```

**3. Input Validation Middleware**
```python
from pydantic import BaseModel, ValidationError

@app.before_request
def validate_request():
    if request.method == 'POST':
        try:
            schema = get_schema_for_endpoint(request.endpoint)
            schema(**request.json)
        except ValidationError as e:
            return jsonify({"error": "Invalid input", "details": e.errors()}), 400
```

**4. Comprehensive Testing**
```bash
# Add pytest test suite
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_model_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api_handlers.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_generation_flow.py
‚îÇ   ‚îî‚îÄ‚îÄ test_batch_processing.py
‚îî‚îÄ‚îÄ e2e/
    ‚îî‚îÄ‚îÄ test_full_workflow.py

# Target: 80%+ code coverage
pytest --cov=backend --cov-report=html
```

**5. Monitoring & Logging**
```python
# Add structured logging with ELK stack
import structlog

logger = structlog.get_logger()

@app.route('/generate', methods=['POST'])
def generate():
    logger.info("generation_started", 
                prompt=data['description'],
                user_id=get_user_id(),
                timestamp=datetime.now())
    # ... generation logic
    logger.info("generation_completed",
                duration=elapsed_time,
                success=True)
```

#### Medium-Term Enhancements (3-6 months)

**1. User Authentication & Authorization**
```python
# Add JWT-based authentication
from flask_jwt_extended import JWTManager, jwt_required, create_access_token

app.config['JWT_SECRET_KEY'] = os.getenv('JWT_SECRET')
jwt = JWTManager(app)

@app.route('/generate', methods=['POST'])
@jwt_required()
def generate():
    user_id = get_jwt_identity()
    # Check user quota, rate limits, etc.
```

**2. Database Integration**
```python
# Add PostgreSQL for persistence
from sqlalchemy import create_engine, Column, Integer, String, DateTime
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()

class Generation(Base):
    __tablename__ = 'generations'
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer)
    prompt = Column(String)
    image_url = Column(String)
    created_at = Column(DateTime, default=datetime.utcnow)
    parameters = Column(JSON)
```

**3. Advanced Features**
- **Style Transfer:** Apply different architectural styles to existing plans
- **Room Editing:** Interactive editing of generated floor plans
- **Constraint Specification:** Specify exact room dimensions and adjacencies
- **Multi-Floor Support:** Generate multi-story buildings

**4. Model Improvements**
- **Higher Resolution:** Train 1024√ó1024 model using SDXL
- **ControlNet Integration:** Add edge/sketch conditioning for better control
- **Inpainting:** Allow users to modify specific regions
- **Upscaling:** Integrate Real-ESRGAN for 4√ó upscaling

**5. Frontend Enhancements**
- **Generation History:** View and manage past generations
- **Favorites:** Save and organize favorite designs
- **Sharing:** Share generations via unique URLs
- **Collaboration:** Multi-user editing and commenting

#### Long-Term Vision (6-12 months)

**1. 3D Visualization**
```javascript
// Integrate Three.js for 3D rendering
import * as THREE from 'three';

function generate3DModel(floorPlan) {
    const scene = new THREE.Scene();
    const geometry = extrudeFloorPlan(floorPlan);
    const mesh = new THREE.Mesh(geometry, material);
    scene.add(mesh);
    return scene;
}
```

**2. AR/VR Integration**
- WebXR API for browser-based AR
- Export to Unity/Unreal Engine
- Virtual walkthroughs of generated plans

**3. AI-Powered Recommendations**
```python
# Add recommendation engine
class FloorPlanRecommender:
    def recommend_similar(self, floor_plan_id):
        # Use CLIP embeddings for similarity search
        embedding = self.encode_floor_plan(floor_plan_id)
        similar = self.vector_db.search(embedding, k=10)
        return similar
    
    def suggest_improvements(self, floor_plan):
        # Use GPT-4 to analyze and suggest improvements
        analysis = gpt4.analyze(floor_plan)
        return analysis['suggestions']
```

**4. Multi-Modal Input**
```python
# Support sketch-to-floor-plan
@app.route('/generate/from-sketch', methods=['POST'])
def generate_from_sketch():
    sketch_image = request.files['sketch']
    # Use ControlNet with sketch conditioning
    result = controlnet_pipeline(
        prompt=request.form['description'],
        image=sketch_image,
        controlnet_conditioning_scale=0.8
    )
    return jsonify(result)
```

**5. Enterprise Features**
- **Team Collaboration:** Shared workspaces and projects
- **Version Control:** Track changes and iterations
- **Export Formats:** DWG, DXF, PDF, SVG
- **API Rate Limiting:** Tiered pricing with usage quotas
- **White-Label:** Customizable branding for agencies

**6. Mobile Applications**
```dart
// Flutter mobile app
class FloorMindApp extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      home: GeneratorScreen(),
    );
  }
}
```

### Recommended Next Steps

**For Immediate Deployment:**
1. Add authentication and rate limiting
2. Implement request queuing
3. Set up monitoring (Prometheus + Grafana)
4. Deploy to cloud (AWS/GCP/Azure)
5. Add HTTPS with Let's Encrypt

**For Product Development:**
1. Conduct user research and usability testing
2. Implement user feedback mechanisms
3. Add analytics to track usage patterns
4. Create marketing website and documentation
5. Develop pricing and monetization strategy

**For Technical Improvement:**
1. Refactor training scripts into modular components
2. Add comprehensive unit and integration tests
3. Implement CI/CD pipeline (GitHub Actions)
4. Set up automated model evaluation
5. Create developer documentation and API reference

### Conclusion

FloorMind represents a solid foundation for an AI-powered architectural design tool. The core technology works well, the architecture is sound, and the user experience is intuitive. With focused improvements in scalability, security, and feature richness, FloorMind has the potential to become a valuable tool for architects, designers, and real estate professionals.

The project successfully demonstrates that:
- Fine-tuned diffusion models can generate high-quality architectural floor plans
- Natural language interfaces make complex design tools accessible
- Full-stack AI applications can be built with modern web technologies
- Production-ready ML systems require careful attention to performance, error handling, and user experience

**Final Assessment:** FloorMind is production-ready for small-scale deployment (single user, low traffic) but requires additional work for enterprise-scale deployment (multi-user, high traffic, mission-critical applications).

---

## Appendix

### File Structure Reference

```
FloorMind/
‚îú‚îÄ‚îÄ backend/                    # Backend application
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.py             # Main Flask application (500 lines)
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_loader.py    # Model management (300 lines)
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate.py        # Generation endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py        # Metrics endpoints
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py         # Utility functions
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/        # Reusable components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/             # Page components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js         # API client (500 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx            # Main app component
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js           # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ public/                # Static assets
‚îÇ   ‚îî‚îÄ‚îÄ package.json           # Dependencies
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # Automation scripts
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_best_fine.py # Production training (1200 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_production.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_qlora.py
‚îÇ   ‚îú‚îÄ‚îÄ testing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api.py        # API tests
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verify_setup.py    # Setup verification
‚îÇ   ‚îî‚îÄ‚îÄ deployment/
‚îÇ       ‚îî‚îÄ‚îÄ start_server.sh    # Server startup
‚îÇ
‚îú‚îÄ‚îÄ data/                       # Data processing
‚îÇ   ‚îú‚îÄ‚îÄ process_cubicasa5k_improved.py  # Dataset processor (900 lines)
‚îÇ   ‚îú‚îÄ‚îÄ dataset_manager.py     # Dataset management
‚îÇ   ‚îî‚îÄ‚îÄ metadata.csv           # Training metadata
‚îÇ
‚îú‚îÄ‚îÄ models/                     # AI models
‚îÇ   ‚îî‚îÄ‚îÄ active/
‚îÇ       ‚îî‚îÄ‚îÄ floormind_pipeline/  # Fine-tuned model (5GB)
‚îÇ           ‚îú‚îÄ‚îÄ unet/          # 3.3GB
‚îÇ           ‚îú‚îÄ‚îÄ text_encoder/  # 1.3GB
‚îÇ           ‚îú‚îÄ‚îÄ vae/           # 319MB
‚îÇ           ‚îú‚îÄ‚îÄ tokenizer/
‚îÇ           ‚îî‚îÄ‚îÄ scheduler/
‚îÇ
‚îú‚îÄ‚îÄ config/                     # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ backend_config.py
‚îÇ   ‚îî‚îÄ‚îÄ training_config_a100.json
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ .env.example               # Environment template
‚îî‚îÄ‚îÄ PROJECT_STRUCTURE.txt      # Project overview
```

### Key Metrics

- **Total Lines of Code:** ~15,000
- **Backend:** ~3,000 lines (Python)
- **Frontend:** ~5,000 lines (JavaScript/React)
- **Training:** ~5,000 lines (Python)
- **Data Processing:** ~2,000 lines (Python)

- **Model Size:** 5GB (compressed)
- **Dataset Size:** 5,050 images (~2.5GB)
- **Training Time:** 4-6 hours (A100 GPU)
- **Inference Time:** 2-5 seconds (GPU), 30-60 seconds (CPU)

- **API Endpoints:** 6
- **React Components:** 15+
- **Test Scripts:** 5
- **Configuration Files:** 3

### Contact & Support

For questions, issues, or contributions, please refer to the project repository or contact the development team.

---

**Document Version:** 1.0  
**Last Updated:** November 28, 2025  
**Author:** FloorMind Development Team  
**License:** [Specify License]

