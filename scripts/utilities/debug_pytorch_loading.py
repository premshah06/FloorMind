#!/usr/bin/env python3
"""
Debug PyTorch and Diffusers Loading
Test script to identify the segmentation fault issue
"""

import os
import sys
import traceback

def test_basic_imports():
    """Test basic library imports"""
    print("ğŸ” Testing basic imports...")
    
    try:
        import torch
        print(f"âœ… PyTorch imported successfully: {torch.__version__}")
        print(f"   CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   CUDA device count: {torch.cuda.device_count()}")
    except Exception as e:
        print(f"âŒ PyTorch import failed: {e}")
        return False
    
    try:
        import diffusers
        print(f"âœ… Diffusers imported successfully: {diffusers.__version__}")
    except Exception as e:
        print(f"âŒ Diffusers import failed: {e}")
        return False
    
    return True

def test_model_path():
    """Test model path and files"""
    print("\nğŸ” Testing model path...")
    
    model_path = "./google"
    
    if not os.path.exists(model_path):
        print(f"âŒ Model path not found: {model_path}")
        return False
    
    print(f"âœ… Model path exists: {model_path}")
    
    # Check required files
    required_files = ["model.safetensors", "tokenizer_config.json", "scheduler_config.json"]
    missing_files = []
    
    for file in required_files:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            print(f"âœ… {file}: {size:,} bytes")
        else:
            missing_files.append(file)
            print(f"âŒ {file}: missing")
    
    if missing_files:
        print(f"âŒ Missing files: {missing_files}")
        return False
    
    return True

def test_simple_tensor():
    """Test simple tensor operations"""
    print("\nğŸ” Testing simple tensor operations...")
    
    try:
        import torch
        
        # Create a simple tensor
        x = torch.randn(2, 3)
        print(f"âœ… Created tensor: {x.shape}")
        
        # Test device movement
        if torch.cuda.is_available():
            try:
                x_cuda = x.cuda()
                print(f"âœ… Moved tensor to CUDA: {x_cuda.device}")
                x_cpu = x_cuda.cpu()
                print(f"âœ… Moved tensor back to CPU: {x_cpu.device}")
            except Exception as e:
                print(f"âš ï¸  CUDA operations failed: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Tensor operations failed: {e}")
        traceback.print_exc()
        return False

def test_diffusers_components():
    """Test individual diffusers components"""
    print("\nğŸ” Testing diffusers components...")
    
    try:
        from diffusers import UNet2DConditionModel, DDPMScheduler
        from transformers import CLIPTextModel, CLIPTokenizer
        
        print("âœ… Diffusers components imported successfully")
        
        # Test loading individual components
        model_path = "./google"
        
        try:
            print("ğŸ”„ Loading tokenizer...")
            tokenizer = CLIPTokenizer.from_pretrained(model_path, local_files_only=True)
            print("âœ… Tokenizer loaded")
        except Exception as e:
            print(f"âŒ Tokenizer loading failed: {e}")
            return False
        
        try:
            print("ğŸ”„ Loading scheduler...")
            scheduler = DDPMScheduler.from_pretrained(model_path, subfolder="scheduler", local_files_only=True)
            print("âœ… Scheduler loaded")
        except Exception as e:
            print(f"âŒ Scheduler loading failed: {e}")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Diffusers components test failed: {e}")
        traceback.print_exc()
        return False

def test_pipeline_loading():
    """Test pipeline loading with safe settings"""
    print("\nğŸ” Testing pipeline loading...")
    
    try:
        from diffusers import StableDiffusionPipeline
        import torch
        
        model_path = "./google"
        
        print("ğŸ”„ Loading pipeline with safe settings...")
        
        # Try with minimal settings first
        pipeline = StableDiffusionPipeline.from_pretrained(
            model_path,
            torch_dtype=torch.float32,  # Use float32 for stability
            safety_checker=None,
            requires_safety_checker=False,
            local_files_only=True,
            device_map=None  # Don't auto-assign devices
        )
        
        print("âœ… Pipeline loaded successfully")
        
        # Test moving to CPU explicitly
        pipeline = pipeline.to("cpu")
        print("âœ… Pipeline moved to CPU")
        
        return True
        
    except Exception as e:
        print(f"âŒ Pipeline loading failed: {e}")
        traceback.print_exc()
        return False

def main():
    """Run all tests"""
    print("ğŸ  FloorMind PyTorch Loading Debug")
    print("=" * 50)
    
    tests = [
        ("Basic Imports", test_basic_imports),
        ("Model Path", test_model_path),
        ("Simple Tensor", test_simple_tensor),
        ("Diffusers Components", test_diffusers_components),
        ("Pipeline Loading", test_pipeline_loading)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} crashed: {e}")
            traceback.print_exc()
            results[test_name] = False
    
    # Summary
    print(f"\n{'='*50}")
    print("ğŸ“Š Test Results Summary:")
    print("=" * 50)
    
    for test_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"{status} {test_name}")
    
    total_tests = len(results)
    passed_tests = sum(results.values())
    
    print(f"\nğŸ¯ Overall: {passed_tests}/{total_tests} tests passed")
    
    if passed_tests == total_tests:
        print("ğŸ‰ All tests passed! Model loading should work.")
    else:
        print("âš ï¸  Some tests failed. Check the errors above.")

if __name__ == "__main__":
    main()